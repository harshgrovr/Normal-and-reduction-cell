{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal and Reduction cell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, SeparableConv2D, ZeroPadding2D\n",
    "import tensorflow.keras.models\n",
    "from tensorflow.keras import models\n",
    "import os\n",
    "from tensorflow.keras.layers import Lambda\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 80\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model_2.h5'\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define reduction cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction_cell(img_input, r_img_input_2, filters, kernelSize, strides, i):    \n",
    "\n",
    "    # changing number of filters coming from previous layers to filtersize i.e 32\n",
    "    # h is input_1(0) to the cell\n",
    "    # img_input_2 is input_2(1) to the cell\n",
    "    # Both the input to the cell are same i.e. previous cell output.\n",
    "    # I tried stacking normal and reduction cell and also implemented \n",
    "    #   skip connections but network was too slow to train. so for now keeping N = 1.    \n",
    "\n",
    "    \n",
    "    h = img_input        \n",
    "    h = tensorflow.keras.layers.Conv2D(\n",
    "        filters, (1, 1),\n",
    "        strides=(1, 1),\n",
    "        padding='same')(h)\n",
    "    h = tensorflow.keras.layers.Activation('relu')(h) \n",
    "\n",
    "    r_img_input_2 = h\n",
    "    \n",
    "                    # code used in stacking\n",
    "        \n",
    "        \n",
    "#     r_img_input_2 = tensorflow.keras.layers.Conv2D(filters,\n",
    "#                                                   (1, 1),\n",
    "#                                                   strides=(1, 1),\n",
    "#                                                   name= \"r_input_2_%i\"%i,\n",
    "#                                                   padding='same')(r_img_input_2)\n",
    "    \n",
    "#     r_img_input_2 = tensorflow.keras.layers.Activation('relu')(r_img_input_2) \n",
    "    \n",
    "    # comb 2\n",
    "    \n",
    "    comb_2_0 = tensorflow.keras.layers.AveragePooling2D((3,3),\n",
    "                                                        strides=strides,\n",
    "                                                        padding=\"same\",\n",
    "                                                        name = 'r_comb_2_0_%i'%i)(h)\n",
    "\n",
    "    comb_2_0 = tensorflow.keras.layers.UpSampling2D(size=(2, 2),\n",
    "                                                    data_format=None,\n",
    "                                                    interpolation='nearest')(comb_2_0)    \n",
    "    \n",
    "    comb_2_1 = tensorflow.keras.layers.SeparableConv2D(filters,\n",
    "                                                       (3,3),\n",
    "                                                       strides=strides,\n",
    "                                                       padding='same', \n",
    "                                                       name = 'r_comb_2_1_%i'%i)(r_img_input_2)\n",
    "\n",
    "    comb_2_1 = tensorflow.keras.layers.Activation('relu')(comb_2_1)\n",
    "    \n",
    "    comb_2_1 = tensorflow.keras.layers.UpSampling2D(size=(2, 2),\n",
    "                                                    data_format=None,\n",
    "                                                    interpolation='nearest')(comb_2_1)\n",
    "    \n",
    "    comb_2_2 =  tensorflow.keras.layers.add([comb_2_0, comb_2_1])\n",
    "    \n",
    "    # comb 3\n",
    "    \n",
    "    comb_3_0 = tensorflow.keras.layers.MaxPooling2D((3, 3),\n",
    "                                                    strides=(2, 2),\n",
    "                                                    padding='same',  \n",
    "                                                    name = 'r_comb_3_0_%i'%i)(h)\n",
    "\n",
    "    comb_3_0 = tensorflow.keras.layers.UpSampling2D(size=(2, 2),\n",
    "                                                    data_format=None,\n",
    "                                                    interpolation='nearest')(comb_3_0)\n",
    "    \n",
    "    comb_3_1 = tensorflow.keras.layers.MaxPooling2D((3, 3),\n",
    "                                                    strides=(2, 2),\n",
    "                                                    padding='same', \n",
    "                                                    name = 'r_comb_3_1_%i'%i)(r_img_input_2)\n",
    "    \n",
    "    comb_3_1 = tensorflow.keras.layers.UpSampling2D(size=(2, 2),\n",
    "                                                    data_format=None, \n",
    "                                                    interpolation='nearest')(comb_3_1)\n",
    "\n",
    "    comb_3_2 = tensorflow.keras.layers.add([comb_3_0, comb_3_1])\n",
    "    \n",
    "    \n",
    "    #comb 4\n",
    "    \n",
    "    comb_4_0 = tensorflow.keras.layers.MaxPooling2D((3, 3),\n",
    "                                                    strides=(2, 2),\n",
    "                                                    padding='same',\n",
    "                                                    name = 'r_comb_4_0_%i'%i)(h)\n",
    "    \n",
    "    comb_4_0 = tensorflow.keras.layers.UpSampling2D(size=(2, 2),\n",
    "                                                    data_format=None,\n",
    "                                                    interpolation='nearest')(comb_4_0)\n",
    "\n",
    "    \n",
    "    comb_4_1 = tensorflow.keras.layers.SeparableConv2D(filters,\n",
    "                                                       (7,7),\n",
    "                                                       strides=strides,\n",
    "                                                       padding='same',\n",
    "                                                       name = 'r_comb_4_1_%i'%i)(comb_2_2)\n",
    "\n",
    "    comb_4_1 = tensorflow.keras.layers.Activation('relu')(comb_4_1)\n",
    "    \n",
    "    comb_4_1 = tensorflow.keras.layers.UpSampling2D(size=(2, 2), \n",
    "                                                    data_format=None, \n",
    "                                                    interpolation='nearest')(comb_4_1)\n",
    "    \n",
    "\n",
    "    comb_4_2 = tensorflow.keras.layers.add([comb_4_0, comb_4_1])\n",
    "    \n",
    "    \n",
    "     #comb 5\n",
    "    \n",
    "    comb_5_0 = tensorflow.keras.layers.SeparableConv2D(filters,\n",
    "                                                       (7,7),\n",
    "                                                       strides=strides,\n",
    "                                                       padding='same',\n",
    "                                                       name = 'r_comb_5_0_%i'%i)(h)\n",
    "    \n",
    "    comb_5_0 = tensorflow.keras.layers.Activation('relu')(comb_5_0)\n",
    "    \n",
    "    comb_5_0 = tensorflow.keras.layers.UpSampling2D(size=(2, 2),\n",
    "                                                    data_format=None,\n",
    "                                                    interpolation='nearest')(comb_5_0)\n",
    "    \n",
    "  \n",
    "    comb_5_1 = tensorflow.keras.layers.AveragePooling2D((3,3),\n",
    "                                                        strides=strides,\n",
    "                                                        padding=\"same\",\n",
    "                                                        name = 'r_comb_5_1_%i'%i)(r_img_input_2)\n",
    "    \n",
    "    comb_5_1 = tensorflow.keras.layers.UpSampling2D(size=(2, 2),\n",
    "                                                    data_format=None,\n",
    "                                                    interpolation='nearest')(comb_5_1)\n",
    "\n",
    "    comb_5_2 = tensorflow.keras.layers.add([comb_5_0, comb_5_1])\n",
    "    \n",
    "    # comb 6\n",
    "         \n",
    "    comb_6_0 = tensorflow.keras.layers.SeparableConv2D(filters,\n",
    "                                                       (3,3),\n",
    "                                                       strides=strides,\n",
    "                                                       padding='same', \n",
    "                                                       name = 'r_comb_6_0_%i'%i)(comb_3_2)\n",
    "    \n",
    "    comb_6_0 = tensorflow.keras.layers.Activation('relu')(comb_6_0)\n",
    "    \n",
    "    comb_6_0 = tensorflow.keras.layers.UpSampling2D(size=(2, 2),\n",
    "                                                    data_format=None,\n",
    "                                                    interpolation='nearest')(comb_6_0)\n",
    "    \n",
    "    \n",
    "    comb_6_1 = tensorflow.keras.layers.Conv2D(filters,\n",
    "                                              (1,7),\n",
    "                                              strides=strides,\n",
    "                                              padding='same', \n",
    "                                              name = 'r_comb_6_1_1_%i'%i)(h)\n",
    "    \n",
    "    comb_6_1 = tensorflow.keras.layers.Activation('relu')(comb_6_1)\n",
    "    \n",
    "    comb_6_1 = tensorflow.keras.layers.UpSampling2D(size=(2, 2),\n",
    "                                                    data_format=None, \n",
    "                                                    interpolation='nearest')(comb_6_1)\n",
    "    \n",
    "    comb_6_1 = tensorflow.keras.layers.Conv2D(filters,\n",
    "                                              (7,1),\n",
    "                                              strides=strides,\n",
    "                                              padding='same', \n",
    "                                              name = 'r_comb_6_1_2_%i'%i)(comb_6_1)\n",
    "    \n",
    "    comb_6_1 = tensorflow.keras.layers.Activation('relu')(comb_6_1)    \n",
    "    \n",
    "    comb_6_1 = tensorflow.keras.layers.UpSampling2D(size=(2, 2), \n",
    "                                                    data_format=None, \n",
    "                                                    interpolation='nearest')(comb_6_1)\n",
    "    \n",
    "    comb_6_2 = tensorflow.keras.layers.add([comb_6_0, comb_6_1])\n",
    "    \n",
    "    comb_7_2 = tensorflow.keras.layers.concatenate([comb_4_2, comb_5_2, comb_6_2])    \n",
    "        \n",
    "    return comb_7_2, img_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define normal cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_cell(img_input,img_input_2, filters, kernelSize, strides, i):\n",
    "    \n",
    "    # changing number of filters coming from previous layers to filtersize i.e 32\n",
    "    # h is input_1(0) to the cell\n",
    "    # img_input_2 is input_2(1) to the cell\n",
    "    # Both the input to the cell are same i.e. previous cell output.\n",
    "   \n",
    "    h  = img_input\n",
    "    \n",
    "    h = tensorflow.keras.layers.Conv2D(\n",
    "            filters, (1, 1),\n",
    "            strides=(1, 1),\n",
    "            padding='same')(h)\n",
    "    \n",
    "    h = tensorflow.keras.layers.Activation('relu')(h)   \n",
    "        \n",
    "    img_input_2  = h       \n",
    "    \n",
    "    \n",
    "# commented out code used in stacking\n",
    "        \n",
    "        \n",
    "#     n_img_input_2 = tensorflow.keras.layers.Conv2D(filters,\n",
    "#                                                   (1, 1),\n",
    "#                                                   strides=(1, 1),\n",
    "#                                                   name= \"r_input_2_%i\"%i,\n",
    "#                                                   padding='same')(img_input_2)\n",
    "    \n",
    "#     n_img_input_2 = tensorflow.keras.layers.Activation('relu')(img_input_2) \n",
    "    \n",
    "    \n",
    "    # comb 2\n",
    "    comb_2_0 = tensorflow.keras.layers.AveragePooling2D((3,3),\n",
    "                                                        strides=strides,\n",
    "                                                        name='n_comb_2_0_%i' % i,\n",
    "                                                        padding=\"same\")(h)\n",
    "        \n",
    "\n",
    "    comb_2_1 = tensorflow.keras.layers.MaxPooling2D((3, 3),\n",
    "                                                    strides=(1, 1),\n",
    "                                                    padding='same',\n",
    "                                                    name='n_comb_2_1_%i' % i,)(h)\n",
    "\n",
    "    comb_2_2 = tensorflow.keras.layers.add([comb_2_0, comb_2_1])\n",
    "\n",
    "    # comb 3        \n",
    "    comb_3_0 = h\n",
    "    \n",
    "    comb_3_1 = tensorflow.keras.layers.AveragePooling2D((3,3),\n",
    "                                                        strides=(1,1),\n",
    "                                                        name='n_comb_3_1_%i' % i,\n",
    "                                                        padding=\"same\")(img_input_2)\n",
    "\n",
    "    comb_3_2 = tensorflow.keras.layers.add([comb_3_0, comb_3_1])\n",
    "\n",
    "    # comb 4\n",
    "    comb_4_1 = tensorflow.keras.layers.SeparableConv2D(filters,\n",
    "                                                       (3,3),\n",
    "                                                       padding = 'same',\n",
    "                                                       name='n_comb_4_1_%i' % i)(img_input_2)\n",
    "\n",
    "    comb_4_1 = tensorflow.keras.layers.Activation('relu')(comb_4_1)\n",
    "\n",
    "\n",
    "    comb_4_0 = tensorflow.keras.layers.SeparableConv2D(filters,\n",
    "                                                       (5, 5),\n",
    "                                                       padding = 'same',\n",
    "                                                       name='n_comb_4_0_%i' % i)(comb_2_2)\n",
    "\n",
    "    comb_4_0 = tensorflow.keras.layers.Activation('relu')(comb_4_0)\n",
    "\n",
    "    comb_4_2 =  tensorflow.keras.layers.add([comb_4_0, comb_4_1])\n",
    "\n",
    "    # comb 5\n",
    "    comb_5_0 = tensorflow.keras.layers.SeparableConv2D(filters,\n",
    "                                                       (3,3),\n",
    "                                                       padding = 'same',\n",
    "                                                       name='n_comb_5_0_%i' % i)(comb_2_2)\n",
    "\n",
    "    comb_5_0 = tensorflow.keras.layers.Activation('relu')(comb_5_0)\n",
    "\n",
    "    comb_5_1 = img_input_2\n",
    "\n",
    "    comb_5_2 = tensorflow.keras.layers.add([comb_5_0, comb_5_1])\n",
    "\n",
    "    # comb 6\n",
    "    comb_6_0 = tensorflow.keras.layers.AveragePooling2D((3,3),\n",
    "                                                        strides=strides,\n",
    "                                                        name='n_comb_6_0_%i' % i,\n",
    "                                                        padding=\"same\")(comb_4_2)\n",
    "\n",
    "    comb_6_1 = tensorflow.keras.layers.SeparableConv2D(filters,\n",
    "                                                       (3,3),\n",
    "                                                       padding = 'same',\n",
    "                                                       name='n_comb_6_1_%i' % i)(h)\n",
    "\n",
    "    comb_6_1 = tensorflow.keras.layers.Activation('relu')(comb_6_1)\n",
    "\n",
    "    comb_6_2 = tensorflow.keras.layers.add([comb_6_0, comb_6_1])\n",
    "\n",
    "    comb_7_out = tensorflow.keras.layers.concatenate([comb_3_2, comb_5_2, comb_6_2])\n",
    "    \n",
    "    return comb_7_out, img_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model(AmoebaNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amoebaNet(input_tensor):\n",
    "    \n",
    "    i=0;\n",
    "    \n",
    "    h = tensorflow.keras.layers.Conv2D(filters, (3, 3),\n",
    "                                       strides=(2, 2),\n",
    "                                       padding='same',\n",
    "                                       input_shape=(32,32,3))(input_tensor)\n",
    "    \n",
    "    h = tensorflow.keras.layers.Activation('relu')(h)    \n",
    "    \n",
    "    h = tensorflow.keras.layers.UpSampling2D(size=(2, 2),\n",
    "                                             data_format=None,\n",
    "                                             interpolation='nearest')(h)    \n",
    "    \n",
    "    output_1,input_h = reduction_cell(h, h,\n",
    "                                    filters = 32,\n",
    "                                    kernelSize = (3,3),\n",
    "                                    strides =(2,2), i=1)\n",
    "        \n",
    "# commented out code used in stacking\n",
    "\n",
    "#     output_2,input_h = reduction_cell(h, output_1,\n",
    "#                                     filters = 32,\n",
    "#                                     kernelSize = (3,3),\n",
    "#                                     strides =(2,2), i=2)\n",
    "\n",
    "    output_3,input_h = normal_cell(output_1, h,\n",
    "                                 filters = 32,\n",
    "                                 kernelSize = (3,3) ,\n",
    "                                 strides =(1,1), i=3)\n",
    "    \n",
    "#     output,input_h = normal_cell(output_2, output_3,\n",
    "#                                  filters = 32,\n",
    "#                                  kernelSize = (3,3) ,\n",
    "#                                  strides =(1,1), i=4)\n",
    "\n",
    "\n",
    "    output = tensorflow.keras.layers.Flatten()(output_3)\n",
    "    \n",
    "    softmax_output = tensorflow.keras.layers.Dense(10, activation='softmax')(output)        \n",
    "    \n",
    "    model = models.Model(input_tensor, softmax_output, name='ameoba net')        \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "filters =32\n",
    "x = x_train[:batch_size]\n",
    "x=tf.to_float(x, name='ToFloat')\n",
    "img_input = tensorflow.keras.layers.Input(shape = (32,32,3), batch_size =batch_size)\n",
    "print(img_input.shape)\n",
    "model = amoebaNet(img_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           (80, 32, 32, 3)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (80, 16, 16, 32)     896         input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_366 (Activation)     (80, 16, 16, 32)     0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_324 (UpSampling2D (80, 32, 32, 32)     0           activation_366[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (80, 32, 32, 32)     1056        up_sampling2d_324[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_367 (Activation)     (80, 32, 32, 32)     0           conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "r_comb_2_1_1 (SeparableConv2D)  (80, 16, 16, 32)     1344        activation_367[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "r_comb_2_0_1 (AveragePooling2D) (80, 16, 16, 32)     0           activation_367[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_368 (Activation)     (80, 16, 16, 32)     0           r_comb_2_1_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "r_comb_3_0_1 (MaxPooling2D)     (80, 16, 16, 32)     0           activation_367[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "r_comb_3_1_1 (MaxPooling2D)     (80, 16, 16, 32)     0           activation_367[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "r_comb_6_1_1_1 (Conv2D)         (80, 16, 16, 32)     7200        activation_367[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_325 (UpSampling2D (80, 32, 32, 32)     0           r_comb_2_0_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_326 (UpSampling2D (80, 32, 32, 32)     0           activation_368[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_327 (UpSampling2D (80, 32, 32, 32)     0           r_comb_3_0_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_328 (UpSampling2D (80, 32, 32, 32)     0           r_comb_3_1_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_372 (Activation)     (80, 16, 16, 32)     0           r_comb_6_1_1_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_245 (Add)                   (80, 32, 32, 32)     0           up_sampling2d_325[0][0]          \n",
      "                                                                 up_sampling2d_326[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_246 (Add)                   (80, 32, 32, 32)     0           up_sampling2d_327[0][0]          \n",
      "                                                                 up_sampling2d_328[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_334 (UpSampling2D (80, 32, 32, 32)     0           activation_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "r_comb_4_1_1 (SeparableConv2D)  (80, 16, 16, 32)     2624        add_245[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "r_comb_5_0_1 (SeparableConv2D)  (80, 16, 16, 32)     2624        activation_367[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "r_comb_6_0_1 (SeparableConv2D)  (80, 16, 16, 32)     1344        add_246[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "r_comb_6_1_2_1 (Conv2D)         (80, 16, 16, 32)     7200        up_sampling2d_334[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "r_comb_4_0_1 (MaxPooling2D)     (80, 16, 16, 32)     0           activation_367[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_369 (Activation)     (80, 16, 16, 32)     0           r_comb_4_1_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_370 (Activation)     (80, 16, 16, 32)     0           r_comb_5_0_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "r_comb_5_1_1 (AveragePooling2D) (80, 16, 16, 32)     0           activation_367[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_371 (Activation)     (80, 16, 16, 32)     0           r_comb_6_0_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_373 (Activation)     (80, 16, 16, 32)     0           r_comb_6_1_2_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_329 (UpSampling2D (80, 32, 32, 32)     0           r_comb_4_0_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_330 (UpSampling2D (80, 32, 32, 32)     0           activation_369[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_331 (UpSampling2D (80, 32, 32, 32)     0           activation_370[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_332 (UpSampling2D (80, 32, 32, 32)     0           r_comb_5_1_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_333 (UpSampling2D (80, 32, 32, 32)     0           activation_371[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_335 (UpSampling2D (80, 32, 32, 32)     0           activation_373[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_247 (Add)                   (80, 32, 32, 32)     0           up_sampling2d_329[0][0]          \n",
      "                                                                 up_sampling2d_330[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_248 (Add)                   (80, 32, 32, 32)     0           up_sampling2d_331[0][0]          \n",
      "                                                                 up_sampling2d_332[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_249 (Add)                   (80, 32, 32, 32)     0           up_sampling2d_333[0][0]          \n",
      "                                                                 up_sampling2d_335[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (80, 32, 32, 96)     0           add_247[0][0]                    \n",
      "                                                                 add_248[0][0]                    \n",
      "                                                                 add_249[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (80, 32, 32, 32)     3104        concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_374 (Activation)     (80, 32, 32, 32)     0           conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "n_comb_2_0_3 (AveragePooling2D) (80, 32, 32, 32)     0           activation_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "n_comb_2_1_3 (MaxPooling2D)     (80, 32, 32, 32)     0           activation_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_250 (Add)                   (80, 32, 32, 32)     0           n_comb_2_0_3[0][0]               \n",
      "                                                                 n_comb_2_1_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "n_comb_4_0_3 (SeparableConv2D)  (80, 32, 32, 32)     1856        add_250[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "n_comb_4_1_3 (SeparableConv2D)  (80, 32, 32, 32)     1344        activation_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_376 (Activation)     (80, 32, 32, 32)     0           n_comb_4_0_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_375 (Activation)     (80, 32, 32, 32)     0           n_comb_4_1_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "n_comb_5_0_3 (SeparableConv2D)  (80, 32, 32, 32)     1344        add_250[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_252 (Add)                   (80, 32, 32, 32)     0           activation_376[0][0]             \n",
      "                                                                 activation_375[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "n_comb_6_1_3 (SeparableConv2D)  (80, 32, 32, 32)     1344        activation_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "n_comb_3_1_3 (AveragePooling2D) (80, 32, 32, 32)     0           activation_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_377 (Activation)     (80, 32, 32, 32)     0           n_comb_5_0_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "n_comb_6_0_3 (AveragePooling2D) (80, 32, 32, 32)     0           add_252[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_378 (Activation)     (80, 32, 32, 32)     0           n_comb_6_1_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_251 (Add)                   (80, 32, 32, 32)     0           activation_374[0][0]             \n",
      "                                                                 n_comb_3_1_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_253 (Add)                   (80, 32, 32, 32)     0           activation_377[0][0]             \n",
      "                                                                 activation_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_254 (Add)                   (80, 32, 32, 32)     0           n_comb_6_0_3[0][0]               \n",
      "                                                                 activation_378[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (80, 32, 32, 96)     0           add_251[0][0]                    \n",
      "                                                                 add_253[0][0]                    \n",
      "                                                                 add_254[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (80, 98304)          0           concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (80, 10)             983050      flatten_16[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,016,330\n",
      "Trainable params: 1,016,330\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tensorflow.keras.optimizers.RMSprop(lr=0.0003, decay=1e-6, )\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "y_train = y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 212s 4ms/sample - loss: 1.5370 - acc: 0.4564 - val_loss: 1.3619 - val_acc: 0.5199\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 212s 4ms/sample - loss: 1.2042 - acc: 0.5778 - val_loss: 1.1030 - val_acc: 0.6042\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 211s 4ms/sample - loss: 1.0596 - acc: 0.6281 - val_loss: 1.0016 - val_acc: 0.6449\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 211s 4ms/sample - loss: 0.9614 - acc: 0.6651 - val_loss: 0.9879 - val_acc: 0.6521\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 212s 4ms/sample - loss: 0.8895 - acc: 0.6909 - val_loss: 0.9644 - val_acc: 0.6612\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 212s 4ms/sample - loss: 0.8315 - acc: 0.7132 - val_loss: 0.9265 - val_acc: 0.6752\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 212s 4ms/sample - loss: 0.7790 - acc: 0.7310 - val_loss: 0.9510 - val_acc: 0.6711\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 212s 4ms/sample - loss: 0.7325 - acc: 0.7487 - val_loss: 0.9066 - val_acc: 0.6889\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 212s 4ms/sample - loss: 0.6943 - acc: 0.7616 - val_loss: 0.9125 - val_acc: 0.6915\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 212s 4ms/sample - loss: 0.6549 - acc: 0.7748 - val_loss: 0.9151 - val_acc: 0.6856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f460482da20>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(x_test, y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at /home/vikas/Desktop/NewFolder/saved_models/keras_cifar10_trained_model_2.h5 \n"
     ]
    }
   ],
   "source": [
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 10s 1ms/sample - loss: 0.9151 - acc: 0.6856\n",
      "Test loss: 0.9150700416564942\n",
      "Test accuracy: 0.6856\n"
     ]
    }
   ],
   "source": [
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
